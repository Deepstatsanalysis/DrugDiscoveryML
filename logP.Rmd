---
title: "logP"
author: "João Almeida"
date: "16 de Outubro de 2018"
output: html_document
---

set.seed(123)

logp.data<-data%>%filter(assay_id==16590|assay_id==20401)#73

#remove NA
logp.data<-logp.data%>%filter(!is.na(mw_freebase))
logp.data<-logp.data%>%filter(!is.na(psa))
logp.data<-logp.data%>%filter(!is.na(acd_most_apka))
logp.data<-logp.data%>%filter(!is.na(hba))
logp.data<-logp.data%>%filter(!is.na(hbd))
logp.data<-logp.data%>%filter(!is.na(acd_logp))
logp.data<-logp.data%>%filter(!is.na(acd_logd))
logp.data<-logp.data%>%filter(!is.na(rtb))
logp.data<-logp.data%>%filter(!is.na(acd_most_bpka))
logp.data<-logp.data%>%filter(!is.na(mw_monoisotopic))
logp.data<-logp.data%>%filter(!is.na(aromatic_rings))
logp.data<-logp.data%>%filter(!is.na(full_mwt))

logp.data<-logp.data%>%filter(!is.na(standard_value))

logp.data<-logp.data%>%select(mw_freebase, psa,acd_most_apka, acd_most_bpka, hba,hbd,rtb,mw_monoisotopic, aromatic_rings,full_mwt,standard_value) # 76%
logp.data<-logp.data[!duplicated(logp.data),]


#################################random forest############################################
samp <- sample(nrow(logp.data), 0.6 * nrow(logp.data))
logp.train <- logp.data[samp, ]#744
logp.test <- logp.data[-samp, ]#497

#logp random forest terá mlhr sucesso com 7 variaveis
#[1] "acd_most_apka"  "acd_most_bpka"  "aromatic_rings" "psa"           
#[5] "hbd"            "rtb"            "hba"
logp.x.train<-logp.train%>%select(mw_freebase, psa,acd_most_apka, acd_most_bpka, hba,hbd,rtb,mw_monoisotopic, aromatic_rings,full_mwt) # 76%

logp.x.train<-logp.train%>%select( psa, acd_most_bpka, hba,hbd,rtb, aromatic_rings) # 76%
logp.y.train<-logp.train$standard_value


logp.rf.mdl <-randomForest(logp.y.train,x=logp.x.train,mtry=5,ntree=1500)
print(logp.rf.mdl)
varImpPlot(logp.rf.mdl)
importance(logp.rf.mdl)

logp.pred<-predict(logp.rf.mdl,newdata=logp.test)
plot(logp.pred,logp.test$standard_value)
abline(0,1,col="blue")
###MSE propriamente dito, e n previsto como no print rf
logp.rf.PredictionRMSE<-mean((logp.pred-logp.test$standard_value)^2) 
print(logp.rf.PredictionRMSE)
logp.rf.PredictionMAE<-mean(abs(logp.pred-logp.test$standard_value)) 
print(logp.rf.PredictionMAE)


######TUNERF############
logp.rf.mdl.tuned<-tuneRF(logp.x.train,logp.y.train,mtryStart = 3,ntreeTry = 1500, improve = 0.1,doBest = TRUE)

logp.pred.tuned<-predict(logp.rf.mdl.tuned,newdata=logp.test)

plot(logp.pred.tuned,logp.test$standard_value)
abline(0,1,col="blue")
###MSE propriamente dito, e n previsto como no print rf
logp.rf.tuned.PredictionRMSE<-mean((logp.pred.tuned-logp.test$standard_value)^2) 
print(logp.rf.tuned.PredictionRMSE)
logp.rf.tuned.PredictionMAE<-mean(abs(logp.pred.tuned-logp.test$standard_value)) 
print(logp.rf.tuned.PredictionMAE)

# Manual Search
modellist <- list()
for (ntree in c(2000, 2500)) {
  for (mtry in c(8,9)){
    for (nodesize in c(9)){
  set.seed(123)
  fit <- rf.crossValidation(logp.rf.mdl, logp.x.train, p=0.60, n=10, ntree=ntree, mtry=mtry, nodesize=nodesize)# segunda versao cv
  key <- toString(ntree)
  key2 <- toString(mtry)
  key3 <- toString(nodesize)
  
  modellist[[key]][[key2]][[key3]] <- fit$y.rmse
}
  }
}
# compare results
boxplot(modellist[2000][8][9])

modellist$`2500--9--9`
results <- resamples(modellist)
summary(modellist)
dotplot(results)

#################################SVR########################################
logp.modelsvr<-svm(y=logp.y.train,x=logp.x.train)
logp.predict.svr <-predict(logp.modelsvr,logp.x.train)

print(logp.modelsvr)

plot(logp.train$standard_value)
points(logp.predict.svr,col="Red")
logp.modelsvr.error <- logp.train$standard_value-logp.predict.svr
logp.svrPredictionRMSE <-sqrt(mean(logp.modelsvr.error^2))
print (logp.svrPredictionRMSE)#1.26
logp.svrPredictionMAE <-mean(abs(logp.predict.svr-logp.train$standard_value)) 
print (logp.svrPredictionMAE)#0.78


###tune SVR
tc <- tune.control(cross = 10)

logp.svr.tunedresult<-tune(svm,train.x=logp.x.train,train.y=logp.y.train,ranges=list(epsilon=seq(0,1,0.1),cost=2^(2:9)), tunecontrol = tc)
#epsilon cost
#0.1   32 
#voltar a correr o tunedrsult com o seq de 0-0.1, com 0.01 e cost aumentar
logp.svr.tunedresult<-tune(svm,train.x=logp.x.train,train.y=logp.y.train,ranges=list(epsilon=seq(0,0.1,0.01),cost=2^(2:7)), tunecontrol = tc)

print(logp.svr.tunedresult)
plot(logp.svr.tunedresult)

logp.predict.svr.tuned <-predict(logp.svr.tunedresult$best.model,logp.x.train)
logp.modelsvr.error.tuned <- logp.train$standard_value-logp.predict.svr.tuned
svrPrediction.tuned.RMSE <-sqrt(mean(logp.modelsvr.error.tuned^2))
print (svrPrediction.tuned.RMSE)#0.78

svrPrediction.tuned.MAE <-mean(abs(logp.predict.svr.tuned-logp.train$standard_value)) 
print (svrPrediction.tuned.MAE)#0.78


#################################SVR2########################################
logp.x.train<-logp.train%>%select(acd_logd, acd_logp,acd_most_apka, mw_freebase,mw_monoisotopic, aromatic_rings,full_mwt) # 76%
logp.modelsvr<-svm(y=logp.y.train,x=logp.x.train)
logp.predict.svr <-predict(logp.modelsvr,logp.x.train)

print(logp.modelsvr)
str(logp.predict.svr)
plot(logp.train$standard_value)
points(logp.predict.svr,col="Red")
logp.modelsvr.error <- logp.train$standard_value-logp.predict.svr
logp.svrPredictionRMSE <-sqrt(mean(logp.modelsvr.error^2))
print (logp.svrPredictionRMSE)#1.26
logp.svrPredictionMAE <-mean(abs(logp.predict.svr-logp.train$standard_value)) 
print (logp.svrPredictionMAE)#0.78


###tune SVR
tc <- tune.control(cross = 10)

logp.svr.tunedresult<-tune(svm,train.x=logp.x.train,train.y=logp.y.train,ranges=list(epsilon=seq(0,1,0.1),cost=2^(2:9)), tunecontrol = tc)
 
#voltar a correr o tunedrsult com o seq de 0-0.1, com 0.01 e cost aumentar
logp.svr.tunedresult<-tune(svm,train.x=logp.x.train,train.y=logp.y.train,ranges=list(epsilon=seq(0,0.2,0.025),cost=2^(2:7)), tunecontrol = tc, na.fail=na.omit)

print(logp.svr.tunedresult)
plot(logp.svr.tunedresult)

logp.predict.svr.tuned <-predict(logp.svr.tunedresult$best.model,logp.x.train)
logp.modelsvr.error.tuned <- logp.train$standard_value-logp.predict.svr.tuned
svrPrediction.tuned.RMSE <-sqrt(mean(logp.modelsvr.error.tuned^2))
print (svrPrediction.tuned.RMSE)#0.66

svrPrediction.tuned.MAE <-mean(abs(logp.predict.svr.tuned-logp.train$standard_value)) 
print (svrPrediction.tuned.MAE)#0.38

################################BAYES############################################
samp <- sample(nrow(logp.data), 0.6 * nrow(logp.data))
logp.train <- logp.data[samp, ]#744
logp.test <- logp.data[-samp, ]#497

logp.train.net<-logp.train%>%select(mw_freebase, psa,acd_most_apka, acd_most_bpka, hba,hbd,rtb,mw_monoisotopic, aromatic_rings,full_mwt,standard_value) # 76%
logp.test.net<-logp.test%>%select(mw_freebase, psa,acd_most_apka, acd_most_bpka, hba,hbd,rtb,mw_monoisotopic, aromatic_rings,full_mwt,standard_value) # 76%


logp.hc.net <- hc(logp.train.net, debug=TRUE)#hill clibing

# plot network
plot(logp.hc.net)

# fit the network with the data itself
logp.hc.fit <- bn.fit(logp.hc.net, logp.train.net)

logp.hc.predict <-predict(logp.hc.fit,"standard_value",logp.test.net)

table(logp.hc.predict,logp.test.net$standard_value)
plot(logp.hc.predict)
points(logp.test.net$standard_value,col="Red")

logp.modelhc.error <- logp.test.net$standard_value-logp.hc.predict
logp.hc.PredictionRMSE <-sqrt(mean(logp.modelhc.error^2))
print (logp.hc.PredictionRMSE)#1.605

logp.hc.PredictionMAE <-mean(abs(logp.hc.predict-logp.test.net$standard_value))
print (logp.hc.PredictionMAE)#1.605

cbind(predicted=logp.hc.predict,actual=logp.test.net$standard_value)

###########################multivariate Linear regression##############################
plot(log(logp.train$standard_value))#"test"
logp.data<-data%>%select(mw_freebase, psa,acd_most_apka, acd_most_bpka, hba,hbd,acd_logp,acd_logd,heavy_atoms,rtb,hba_lipinski,mw_monoisotopic, aromatic_rings,full_mwt,mw_monoisotopic,hbd_lipinski, standard_value) 
logp.data<-data%>%filter(assay_id==16590|assay_id==20401)#73

logp.data<-logp.data%>%filter(!is.na(mw_freebase))
logp.data<-logp.data%>%filter(!is.na(psa))
logp.data<-logp.data%>%filter(!is.na(acd_most_apka))
logp.data<-logp.data%>%filter(!is.na(acd_most_bpka))
logp.data<-logp.data%>%filter(!is.na(hba))
logp.data<-logp.data%>%filter(!is.na(hbd))
logp.data<-logp.data%>%filter(!is.na(acd_logp))
logp.data<-logp.data%>%filter(!is.na(acd_logd))
logp.data<-logp.data%>%filter(!is.na(rtb))
logp.data<-logp.data%>%filter(!is.na(heavy_atoms))
logp.data<-logp.data%>%filter(!is.na(hba_lipinski))
logp.data<-logp.data%>%filter(!is.na(hbd_lipinski))
logp.data<-logp.data%>%filter(!is.na(mw_monoisotopic))
logp.data<-logp.data%>%filter(!is.na(aromatic_rings))
logp.data<-logp.data%>%filter(!is.na(full_mwt))

logp.data<-logp.data%>%filter(!is.na(standard_value))
samp <- sample(nrow(logp.data), 0.6 * nrow(logp.data))
logp.train <- logp.data[samp, ]#744
logp.test <- logp.data[-samp, ]#497

logp.lin.reg <- lm(log(standard_value) ~ mw_freebase +  psa + acd_most_apka + acd_most_bpka + hba +
                          hbd + rtb+acd_logp+acd_logd+heavy_atoms+hba_lipinski+mw_monoisotopic+aromatic_rings+full_mwt+mw_monoisotopic+hbd_lipinski, data = logp.train )

# Inspect the model
summary(logp.lin.reg)
#r-squared 12% ou variancia explicada pelos preditores
#PR(>|t|) é o p e por isso quanto menor mlhr (especialmente menor que 0,05)

logp.pred.lin <- exp(predict(logp.lin.reg,logp.test))

logp.lin.reg.RMSE <- sqrt(mean((logp.pred.lin-logp.test$standard_value)^2))
print(logp.lin.reg.RMSE)
logp.lin.reg.MAE <- mean(abs(logp.pred.lin-logp.test$standard_value))
print(logp.lin.reg.MAE)

################################# Neural Networks ###################################
logp.data<-data%>%filter(assay_id==16590|assay_id==20401)#73

#remove NA
logp.data<-logp.data%>%filter(!is.na(mw_freebase))
logp.data<-logp.data%>%filter(!is.na(psa))
logp.data<-logp.data%>%filter(!is.na(acd_most_apka))
logp.data<-logp.data%>%filter(!is.na(hba))
logp.data<-logp.data%>%filter(!is.na(hbd))
logp.data<-logp.data%>%filter(!is.na(acd_logp))
logp.data<-logp.data%>%filter(!is.na(acd_logd))
logp.data<-logp.data%>%filter(!is.na(rtb))
logp.data<-logp.data%>%filter(!is.na(acd_most_bpka))
logp.data<-logp.data%>%filter(!is.na(mw_monoisotopic))
logp.data<-logp.data%>%filter(!is.na(aromatic_rings))
logp.data<-logp.data%>%filter(!is.na(full_mwt))

logp.data<-logp.data%>%filter(!is.na(standard_value))
logp.data.NN<-logp.data%>%select(mw_freebase, psa,acd_most_apka, acd_most_bpka, hba,hbd,rtb,mw_monoisotopic, aromatic_rings,full_mwt,standard_value) # 76%

#check if no na is available
apply(logp.data.NN,2,function(x) sum(is.na(x)))#fun?


logp.lm.fit<-glm(standard_value~.,data=logp.train.net)

summary(logp.lm.fit)

logp.pr.lm<-predict(logp.lm.fit,logp.test.net)
logp.MSE.lm<-sum((logp.pr.lm-logp.test.net$standard_value)^2)/nrow(logp.test)
print(logp.MSE.lm)



logp.maxs<-apply(logp.data.NN,2,max)
logp.mins<-apply(logp.data.NN,2,min)

logp.scaled<-as.data.frame(scale(logp.data.NN,center=logp.mins,scale=logp.maxs-logp.mins))

logp.train.NN<-logp.scaled[samp,]
logp.test.NN<-logp.scaled[-samp,]

logp.n<-names(logp.train.NN)
logp.f<-as.formula(paste("standard_value ~",paste(logp.n[!logp.n %in% "standard_value"],collapse = " + ")))
#o y~ n funciona no neuralnet, dai se fazer a formular fora

logp.NN.model<-neuralnet(logp.f,data=logp.train.NN,hidden=c(6,3),linear.output = TRUE)
#algorithm did not converge in 1 of 1 repetition(s) within the stepmax 
#increase stepmax  

#You can increase the stepmax and thereby giving it more time to converge.
#The other option is to adjust the threshold parameter. 
#By default its value is 0.01. Try increasing it to 0.1/0.5. 
#If you change the lifesign to 'full' you can see the threshold values. 
#Keep your threshold value lower than the one you see at the last step. 
#Remember, higher the threshold, lower the accuracy of the model

plot(logp.NN.model)

str(logp.test.NN[,1:10])#retirar o standard_value
logp.pred.NN<-compute(logp.NN.model,logp.test.NN[,1:10])

logp.pred.NN_<-logp.pred.NN$net.result*(max(logp.data.NN$standard_value)-min(logp.data.NN$standard_value))+min(logp.data.NN$standard_value)
logp.pred.NN.response<-(logp.test.NN$standard_value)*(max(logp.data.NN$standard_value)-min(logp.data.NN$standard_value))+min(logp.data.NN$standard_value)



logp.nn.RMSE<-sum((logp.pred.NN.response-logp.pred.NN_)^2)/nrow(logp.test.NN)
print(logp.nn.RMSE)

plot(logp.test.NN$standard_value,logp.pred.NN$net.result,col="blue")
abline(0,1,lwd=2)


#function for cross-validation Neural Network.
logp.cv.NN.error<-NULL
k<-10

pbar <- create_progress_bar('text')
pbar$init(k)

for(i in 1:k){
  index <- sample(1:nrow(logp.data),round(0.9*nrow(logp.data)))
  logp.train.NN.cv <- logp.scaled[index,]
  logp.test.NN.cv <- logp.scaled[-index,]
  
  logp.nn.cv <- neuralnet(logp.f,data=logp.train.NN.cv,hidden=c(6,2),linear.output=T)
  
  logp.pr.nn.cv <- compute(logp.nn.cv,logp.test.NN.cv[,1:10])
  logp.pr.nn.cv <- logp.pr.nn.cv$net.result*(max(logp.data$standard_value)-min(logp.data$standard_value))+min(logp.data$standard_value)
  
  logp.test.cv.r <- (logp.test.NN.cv$standard_value)*(max(logp.data$standard_value)-min(logp.data$standard_value))+min(logp.data$standard_value)
  
  logp.cv.NN.error[i] <- sum((logp.test.cv.r - logp.pr.nn.cv)^2)/nrow(logp.test.NN.cv)
  
  pbar$step()
}

mean(logp.cv.NN.error)

boxplot(logp.cv.NN.error,xlab='MSE NN CV',col='green',
        border='blue',names='CV error (MSE)',
        main='CV error (MSE) for NN',horizontal=TRUE)

######################################TOTAL#######################################
logp.accuracy <- data.frame(Method = c("Random Forest","SVR","HC.Bayes","SVR Tuned","Random forest Tuned","Multiple Linear Regression"),
                               RMSE   = c(logp.rf.PredictionRMSE,logp.svrPredictionRMSE,logp.hc.PredictionRMSE,svrPrediction.tuned.RMSE,logp.rf.tuned.PredictionRMSE,logp.lin.reg.RMSE),
                               MAE    = c(logp.rf.PredictionMAE,logp.svrPredictionMAE,logp.hc.PredictionMAE,svrPrediction.tuned.MAE,logp.rf.tuned.PredictionMAE,logp.lin.reg.MAE)) 



# Round the values and print the table
logp.accuracy$RMSE <- round(logp.accuracy$RMSE,2)
logp.accuracy$MAE <- round(logp.accuracy$MAE,2) 

print (logp.accuracy)
grid.table(logp.accuracy)
png("images/logp.png", height = 40*nrow(logp.accuracy), width = 100*ncol(logp.accuracy))
grid.table(logp.accuracy)
dev.off()

################################### Cross Validation ##########################################

###rf Cross validation 1
logp.rf.cv1<-rfcv(trainy=logp.y.train,trainx=logp.x.train,cv.fold = 5)#1 versao CV
print(mean(logp.rf.cv1$error.cv))

varImpPlot(logp.rf.mdl)
importance(logp.rf.mdl, type=2)

###rf Cross validation 2
logp.rf.cv <- rf.crossValidation(logp.rf.mdl, logp.x.train, p=0.60, n=10, ntree=1500)# segunda versao cv
print(logp.rf.cv)#0.84

logp.rf.cv.tuned <- rf.crossValidation(logp.rf.mdl.tuned, logp.x.train, p=0.10, n=10, ntree=1500)# segunda versao cv
print(logp.rf.cv.tuned)



############CV TOTAL
logp.accuracy.cv<-data.frame(Method=c("Random Forest CV10","Random Forest Tuned CV10","Neural Networks CV20","SVR Tuned CV10")
                             ,RMSE=c(mean(logp.rf.cv$y.rmse),mean(logp.rf.cv.tuned$y.rmse),mean(logp.cv.NN.error),svrPrediction.tuned.RMSE)
                             ,MAE=c(mean(logp.rf.cv$y.mae),mean(logp.rf.cv.tuned$y.mae),0,svrPrediction.tuned.MAE))

logp.accuracy.cv$RMSE <- round(logp.accuracy.cv$RMSE,2)
logp.accuracy.cv$MAE <- round(logp.accuracy.cv$MAE,2) 


print(logp.accuracy.cv)


