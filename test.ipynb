{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python test for machine-learning\n",
    "\n",
    "### Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.svm import SVR\n",
    "import seaborn as sns\n",
    "import io\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('product_adme.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the dataframe created** \n",
    "* evaluating datatypes\n",
    "* evaluating certain columns \n",
    "* filtering data\n",
    "* histogram for numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "data.dtypes\n",
    "#2\n",
    "data['published_type'].describe()\n",
    "#3\n",
    "data[data[\"published_type\"] == \"logP\"]\n",
    "#4\n",
    "data.hist(column=\"standard_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### para filtrar por count é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "teste=data.groupby(\"published_type\").filter(lambda x: len(x) > 2000)\n",
    "#plot\n",
    "teste[\"published_type\"].value_counts().plot(kind='bar')\n",
    "#print list\n",
    "teste[\"published_type\"].value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_eval=data[data[\"published_type\"] == \"logP\"]\n",
    "[data_eval['standard_value'].sum(), # Total sum of the column values\n",
    " data_eval['standard_value'].mean(), # Mean of the column values\n",
    " data_eval['standard_value'].median(), # Median of the column values\n",
    " data_eval['standard_value'].nunique(), # Number of unique entries\n",
    " data_eval['standard_value'].max(), # Maximum of the column values\n",
    " data_eval['standard_value'].min()] # Minimum of the column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(columns=[\"md\", \"cp\",\"cr\",\"at\",\"aa\",\"molregno.2\",\"molregno.1\",\"doc_id.1\",\"doc_id.2\",\"molregno.3\",\"doc_id.1\",\"doc_id.2\"])\n",
    "data=data.drop(columns=[\"src_id.1\",\"chembl_id.1\",\"assay_id.1\",\"record_id.1\"])\n",
    "\n",
    "#selecting for pka\n",
    "data=data[data[\"published_type\"] == 'logP']\n",
    "\n",
    "#keeping interesting columns\n",
    "data=data[[\"max_phase\",\"dosed_ingredient\", \"structure_type\",  \"molecule_type\",\n",
    "\"oral\", \"parenteral\", \"topical\", \"black_box_warning\",\n",
    "\"natural_product\", \"first_in_class\", \"chirality\", \"prodrug\",\n",
    "\"inorganic_flag\", \"usan_year\", \"availability_type\", \"usan_stem\",\n",
    "\"polymer_flag\", \"usan_substem\", \"usan_stem_definition\",\n",
    "\"indication_class\", \"withdrawn_flag\", \"withdrawn_year\",\n",
    "\"withdrawn_country\", \"withdrawn_reason\", \"mw_freebase\", \"alogp\", \"hba\",\n",
    "\"hbd\", \"psa\", \"rtb\", \"ro3_pass\", \"num_ro5_violations\", \"acd_most_apka\",\n",
    "\"acd_most_bpka\", \"acd_logp\", \"acd_logd\", \"molecular_species\",\n",
    "\"full_mwt\", \"aromatic_rings\", \"heavy_atoms\", \"num_alerts\",\n",
    "\"qed_weighted\", \"mw_monoisotopic\",  \"hba_lipinski\",\n",
    "\"hbd_lipinski\", \"num_lipinski_ro5_violations\",\"assay_type\", \"relationship_type\", \"confidence_score\",\"standard_value\"]]\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data\n",
    "#### filtering for pka\n",
    "pka_data_cleaning from [here](https://www.kaggle.com/mnoori/feature-selection-for-mlr-with-python)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df,null_cutoff,published_type):\n",
    "    \n",
    "    #removing duplicate and unmeaninfull columns\n",
    "    df=df.drop(columns=[\"md\", \"cp\",\"cr\",\"at\",\"aa\",\"molregno.2\",\"molregno.1\",\"doc_id.1\",\"doc_id.2\",\"molregno.3\",\"doc_id.1\",\"doc_id.2\"])\n",
    "    df=df.drop(columns=[\"src_id.1\",\"chembl_id.1\",\"assay_id.1\",\"record_id.1\"])\n",
    "    \n",
    "    #selecting for pka\n",
    "    df=df[df[\"published_type\"] == published_type]\n",
    "\n",
    "    #keeping interesting columns\n",
    "    df=df[[\"max_phase\",\"dosed_ingredient\", \"structure_type\",  \"molecule_type\",\n",
    "    \"oral\", \"parenteral\", \"topical\", \"black_box_warning\",\n",
    "    \"natural_product\", \"first_in_class\", \"chirality\", \"prodrug\",\n",
    "    \"inorganic_flag\", \"usan_year\", \"availability_type\", \"usan_stem\",\n",
    "    \"polymer_flag\", \"usan_substem\", \"usan_stem_definition\",\n",
    "    \"indication_class\", \"withdrawn_flag\", \"withdrawn_year\",\n",
    "    \"withdrawn_country\", \"withdrawn_reason\", \"mw_freebase\",\"alogp\",\"hba\",\n",
    "    \"hbd\", \"psa\", \"rtb\", \"ro3_pass\", \"num_ro5_violations\", \"acd_most_apka\",\n",
    "    \"acd_most_bpka\", \"acd_logp\", \"acd_logd\", \"molecular_species\",\n",
    "    \"full_mwt\", \"aromatic_rings\", \"heavy_atoms\", \"num_alerts\",\n",
    "    \"qed_weighted\", \"mw_monoisotopic\",  \"hba_lipinski\",\n",
    "    \"hbd_lipinski\", \"num_lipinski_ro5_violations\",\"assay_type\", \"relationship_type\",\n",
    "    \"confidence_score\",\"standard_value\"]]\n",
    "\n",
    "    #removing outlier far greater than average\n",
    "    if published_type in [\"pKa\"]:\n",
    "        df=df[df[\"standard_value\"]<400]\n",
    "    \n",
    "    #dropping columns with more than a missing values\n",
    "    null_values=df.isnull().sum()\n",
    "    drop_missing_values=null_values[null_values>(null_cutoff*len(df))]\n",
    "    df=df.drop(drop_missing_values.index, axis=1)    \n",
    "\n",
    "    # counting null values in text columns\n",
    "    text_cols_nullcount=df.select_dtypes(include=[\"object\"]).isnull().sum().sort_values(ascending=False)\n",
    "    text_cols_nullcols=text_cols_nullcount.index\n",
    "    for col in text_cols_nullcols:\n",
    "        mostcounts=df[col].value_counts().index.tolist()\n",
    "        df[col]=df[col].fillna(mostcounts[0]) #replacing the missing column in a text with the highest number of values\n",
    "\n",
    "    #missing values in numerical columns \n",
    "    num_cols=df.select_dtypes(include=[\"object\",\"float64\"]).columns #selecting numerical columns\n",
    "    num_null_counts=df[num_cols].isnull().sum().sort_values(ascending=False) #counting null values in columns\n",
    "    num_null_cols=num_null_counts[num_null_counts!=0].index #selecting the ones that have missing values\n",
    "    df=df.fillna(df[num_null_cols].mode().to_dict(orient=\"records\")[0]) #replacing missing with mode\n",
    "\n",
    "    #passing categorical to numerical\n",
    "    df=pd.get_dummies(df, prefix=\"is_\")\n",
    "\n",
    "    #remove duplicates\n",
    "    df=df.drop_duplicates()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pka_data=data_cleaning(data,0.8,'pKa')\n",
    "pka_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logp_data=data_cleaning(data,0.8,'logP')\n",
    "logp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "analisado o gráfico em baixo, vemos que não existe correlação forte de de nenhuma coluna com o alvo - **standard_value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logd_data=data_cleaning(df=data,published_type='logD',null_cutoff=0.8)    \n",
    "logd_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correlation(df,target,corr_cutoff):\n",
    "    data_train=df.sample(frac=0.7,random_state=200)\n",
    "    data_test=df.drop(data_train.index)\n",
    "\n",
    "    data_x=df.drop(columns=[target])\n",
    "    data_y=df[target]\n",
    "\n",
    "    data_x_train=data_train.drop(columns=[target])\n",
    "    data_y_train=data_train[target]\n",
    "\n",
    "    data_x_test=data_test.drop(columns=[target])\n",
    "    data_y_test=data_test[target]\n",
    "    \n",
    "    corr=data_train.corr()\n",
    "    #fig,ax=plt.subplots(figsize=(8,6))\n",
    "    #sns.heatmap(corr)\n",
    "    features=''\n",
    "    features_text=''\n",
    "    if len(corr[target].where(lambda x : x.abs()>corr_cutoff).dropna())>1:\n",
    "        features=corr[target].where(lambda x : x.abs()>corr_cutoff).dropna()\n",
    "        features_text=features.index.str.cat(sep=', ')+'\\n'\n",
    "    else:\n",
    "        features='1'\n",
    "        features_text='None'\n",
    "    #print('The features correlated with target above the threshold %s are %s' %(corr_cutoff,features_text))\n",
    "    return len(features)\n",
    "\n",
    "check_correlation(logd_data,'standard_value',0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "para retirar colunas com variância abaixo de X, mas devolve um np  \n",
    "além disso, temos variaveis \"booleanas\" o que torna complicado aplicar isto pq a variância não há de ser muito grande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "#sel.fit_transform(pka_data_corrected_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def xMlr(df,target,frac=0.7,cv=10):\n",
    "    i=0\n",
    "    mse=0\n",
    "    score=0\n",
    "    while i<cv:\n",
    "        np.random.seed(seed=123)\n",
    "        pka_data_train=df.sample(frac=0.7,random_state=200)\n",
    "        pka_data_test=df.drop(pka_data_train.index)\n",
    "\n",
    "        pka_data_x=df.drop(columns=[target])\n",
    "        pka_data_y=df[target]\n",
    "\n",
    "        pka_data_x_train=df.drop(columns=[target])\n",
    "        pka_data_y_train=df[target]\n",
    "\n",
    "        pka_data_x_test=df.drop(columns=[target])\n",
    "        pka_data_y_test=df[target]\n",
    "        regr = linear_model.LinearRegression()\n",
    "        regr.fit(pka_data_x_train, pka_data_y_train)\n",
    "        #print(regr.coef_)\n",
    "        mse+=(np.mean((regr.predict( pka_data_x_test)-pka_data_y_test)**2))\n",
    "        score+=regr.score(pka_data_x_test, pka_data_y_test)\n",
    "        i+=1\n",
    "    #print(\"RMSE is %s. Score is %s.\" % (mse/cv, score/cv))\n",
    "    return mse/cv, score/cv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE is mean squared error  \n",
    "Explained variance score:   \n",
    "1 is perfect prediction\n",
    "and 0 means that there is no linear relationship\n",
    "between X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xMlr(logd_data,'standard_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xSVR(df,target,frac=0.7,cv=10):\n",
    "    i=0\n",
    "    mse=0\n",
    "    score=0\n",
    "    while i<cv:\n",
    "        np.random.seed(seed=123)\n",
    "        pka_data_train=df.sample(frac=0.7,random_state=200)\n",
    "        pka_data_test=df.drop(pka_data_train.index)\n",
    "\n",
    "        pka_data_x=df.drop(columns=[target])\n",
    "        pka_data_y=df[target]\n",
    "\n",
    "        pka_data_x_train=df.drop(columns=[target])\n",
    "        pka_data_y_train=df[target]\n",
    "\n",
    "        pka_data_x_test=df.drop(columns=[target])\n",
    "        pka_data_y_test=df[target]\n",
    "        clf = SVR(gamma='scale', C=1.0, epsilon=0.1)\n",
    "        clf.fit(pka_data_x_train, pka_data_y_train) \n",
    "        mse+=(np.mean((clf.predict( pka_data_x_test)-pka_data_y_test)**2))\n",
    "        score+=clf.score(pka_data_x_test, pka_data_y_test, sample_weight=None)\n",
    "        i+=1\n",
    "    return \"MSE is %s. Score is %s.\" % (mse/cv, score/cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xSVR(pka_data,'standard_value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_test_train(df,length,cv,null_cutoff,correlation):\n",
    "    result={}\n",
    "    eval_df=df.groupby(\"published_type\").filter(lambda x: len(x) > length)\n",
    "    test_list=eval_df[\"published_type\"].value_counts().index\n",
    "    \n",
    "    for item in test_list:\n",
    "        try:\n",
    "            test_df=data_cleaning(df,null_cutoff,str(item))\n",
    "            if check_correlation(corr_cutoff=correlation,df=test_df,target='standard_value')>1:\n",
    "                result[item]=xMlr(test_df,'standard_value',frac=0.7,cv=cv)\n",
    "        except:\n",
    "            print(item)\n",
    "            continue\n",
    "    return result\n",
    "\n",
    "evaluation_test_train(data,1000,5,0.8,0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
